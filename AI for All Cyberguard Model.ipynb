{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fetch the Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ntrain_sheet_url = 'https://docs.google.com/spreadsheets/d/1_R60tCWgxvUYEAueo0GDAGXBj_hZxehQnofH3vd9D_c/edit?gid=689418515'\ntrain_url = train_sheet_url.replace('/edit?gid=', '/export?format=xlsx&gid=')\ntrain_df = pd.read_excel(train_url)\n\ntest_sheet_url = 'https://docs.google.com/spreadsheets/d/1rPOSIC66IoDTl0DWyvbhcx4g8uswuA4hgJBZBa14TDA/edit?gid=1695626307'\ntest_url = test_sheet_url.replace('/edit?gid=', '/export?format=xlsx&gid=')\ntest_df = pd.read_excel(test_url)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.concat([train_df, test_df], axis=0)\ndf_test = df.copy()\ndf.dropna(inplace=True)\ndf.to_csv(\"base_data.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Embeddings","metadata":{}},{"cell_type":"markdown","source":"### Define LaBSE Model and Embedding Generation Function","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nsbert_model = SentenceTransformer('sentence-transformers/LaBSE')\ndef generate_embeddings_labse(texts):\n    return sbert_model.encode(texts, batch_size=64, show_progress_bar=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define MPNet Model and Embedding Generation Function","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nsbert_model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\ndef generate_embeddings_mpnet(texts):\n    return sbert_model.encode(texts, batch_size=128, show_progress_bar=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Generate and Save Embeddings with Categories","metadata":{}},{"cell_type":"code","source":"embeddings_labse = generate_embeddings_labse(list(df['crimeaditionalinfo'].astype(str)))\nembeddings_labse_df = pd.DataFrame(embeddings_labse)\nembeddings_labse_df['category'] = df['category']\nembeddings_labse_df['sub_category'] = df['sub_category']\nembeddings_labse_df.to_csv('LaBSE.csv', index=False)\n\n\nembeddings_mpnet = generate_embeddings_mpnet(list(df['crimeaditionalinfo'].astype(str)))\nembeddings_mpnet_df = pd.DataFrame(embeddings_mpnet)\nembeddings_mpnet_df['category'] = df['category']\nembeddings_mpnet_df['sub_category'] = df['sub_category']\nembeddings_mpnet_df.to_csv('mpnet.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nembeddings_labse = pd.read_csv('LaBSE.csv')\nembeddings_mpnet = pd.read_csv('mpnet.csv')\n\nembeddings_labse.drop(['category', 'sub_category'], axis=1,inplace=True)\nembeddings_labse.dropna(inplace=True)\n\nembeddings_mpnet.drop(['category', 'sub_category'], axis=1,inplace=True)\nembeddings_mpnet.dropna(inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"from cuml.linear_model import LogisticRegression as cuLogisticRegression\nfrom cuml.ensemble import RandomForestClassifier as cuRandomForestClassifier\nfrom cuml.neighbors import KNeighborsClassifier as cuKNeighborsClassifier\nfrom cuml.ensemble import RandomForestClassifier as cuExtraTreesClassifier  # Use RandomForest for ExtraTrees\nfrom cuml.naive_bayes import GaussianNB as cuGaussianNB\nfrom cuml.svm import SVC\nfrom cuml.naive_bayes import BernoulliNB\nfrom sklearn.ensemble import VotingClassifier\nfrom cuml.multiclass import MulticlassClassifier\nfrom cuml.naive_bayes import MultinomialNB\n\n\nestimators_labse_category = [\n    ('labse_category_log_reg', cuLogisticRegression(C=1.0, solver='qn', max_iter=1000)),\n    ('labse_category_random_forest', cuRandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)),\n    ('labse_category_knn', cuKNeighborsClassifier(n_neighbors=5)),\n    ('labse_category_extra_trees', cuExtraTreesClassifier(n_estimators=200, max_depth=20, random_state=42)),\n    ('labse_category_bernoulli_nb', BernoulliNB(alpha=1.0)),\n    ('labse_category_multi_nb', MultinomialNB())\n]\n\nestimators_mpnet_category = [\n    ('mpnet_category_log_reg', cuLogisticRegression(C=1.0, solver='qn', max_iter=1000)),\n    ('mpnet_category_random_forest', cuRandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)),\n    ('mpnet_category_knn', cuKNeighborsClassifier(n_neighbors=5)),\n    ('mpnet_category_extra_trees', cuExtraTreesClassifier(n_estimators=200, max_depth=20, random_state=42)),\n    ('mpnet_category_bernoulli_nb', BernoulliNB(alpha=1.0)),\n    ('mpnet_category_multi_nb', MultinomialNB())\n]\n\nestimators_labse_sub_category = [\n    ('labse_sub_category_log_reg', cuLogisticRegression(C=1.0, solver='qn', max_iter=1000)),\n    ('labse_sub_category_random_forest', cuRandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)),\n    ('labse_sub_category_knn', cuKNeighborsClassifier(n_neighbors=5)),\n    ('labse_sub_category_extra_trees', cuExtraTreesClassifier(n_estimators=200, max_depth=20, random_state=42)),\n    ('labse_sub_category_bernoulli_nb', BernoulliNB(alpha=1.0)),\n    ('labse_sub_category_multi_nb', MultinomialNB())\n]\n\nestimators_mpnet_sub_category = [\n    ('mpnet_sub_category_log_reg', cuLogisticRegression(C=1.0, solver='qn', max_iter=1000)),\n    ('mpnet_sub_category_random_forest', cuRandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)),\n    ('mpnet_sub_category_knn', cuKNeighborsClassifier(n_neighbors=5)),\n    ('mpnet_sub_category_extra_trees', cuExtraTreesClassifier(n_estimators=200, max_depth=20, random_state=42)),\n    ('mpnet_sub_category_bernoulli_nb', BernoulliNB(alpha=1.0)),\n    ('mpnet_sub_category_multi_nb', MultinomialNB())\n]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model training and inference functions ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\n\ndef train_classifiers(estimators_1, estimators_2, df1, df2, y):\n    \"\"\"\n    Train a set of classifiers on two separate data frames and aggregate their outputs for further training.\n\n    Parameters:\n    - estimators_1: List of tuples (name, model), where each model is trained on `df1`\n    - estimators_2: List of tuples (name, model), where each model is trained on `df2`\n    - df1: DataFrame with features for the first set of estimators\n    - df2: DataFrame with features for the second set of estimators\n    - y: Labels for training the models\n\n    Returns:\n    - Trained estimators_1 and estimators_2, and the final neural network model\n    \"\"\"\n    # Train models on df1\n    for name, model in estimators_1:\n        df = df1.copy()\n        print(f'Training {name} on df1 -> {df.shape}')\n        model.fit(df, y)\n\n    # Aggregate predictions from estimators_1\n    predictions_1 = np.array([np.argmax(model.predict_proba(df1), axis=1) for _, model in estimators_1]).T\n    predictions_1_prob = np.array([np.max(model.predict_proba(df1), axis=1) for _, model in estimators_1]).T\n    \n    df_tmp1 = pd.DataFrame(predictions_1, columns = [name for name, _ in estimators_1])\n    df_tmp2 = pd.DataFrame(predictions_1_prob, columns = [name+'_prob' for name, _ in estimators_1])\n\n    df_x1 = pd.concat([df_tmp1, df_tmp2], axis=1)\n\n    # Train models on df2\n    for name, model in estimators_2:\n        df = df2.copy()\n        print(f'Training {name} on df2 -> {df.shape}')\n        model.fit(df, y)\n\n    # Aggregate predictions from estimators_2\n    predictions_2 = np.array([np.argmax(model.predict_proba(df2), axis=1) for _, model in estimators_2]).T\n    predictions_2_prob = np.array([np.max(model.predict_proba(df2), axis=1) for _, model in estimators_2]).T\n    \n    df_tmp1 = pd.DataFrame(predictions_2, columns = [name for name, _ in estimators_2])\n    df_tmp2 = pd.DataFrame(predictions_2_prob, columns = [name+'_prob' for name, _ in estimators_2])\n\n    df_x2 = pd.concat([df_tmp1, df_tmp2], axis=1)\n    \n    # Concatenate the predictions from both sets of estimators\n    df_total = pd.concat([df1, df2, df_x1, df_x2], axis=1)\n\n    df_total.fillna(0, inplace=True)\n    \n    # Define and compile the final neural network model\n    final_model = models.Sequential([\n        layers.Dense(64, input_dim=df_total.shape[1], activation='relu'),\n        layers.Dense(32, activation='relu'),\n        layers.Dense(len(np.unique(y)), activation='softmax')  # Correct output dimension\n    ])\n    final_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    # Train and evaluate the neural network model\n    y_one_hot = to_categorical(y, num_classes=len(np.unique(y)))\n\n    final_model.fit(df_total, y_one_hot, epochs=10, batch_size=32, verbose=1)\n    final_model.evaluate(df_total, y_one_hot)\n    \n    return estimators_1, estimators_2, final_model\n\n\n\n\ndef make_prediction(estimators_1, estimators_2, final_model, df1, df2):\n    \"\"\"\n    Make predictions using trained classifiers and the final neural network model.\n\n    Parameters:\n    - estimators_1: List of tuples (name, model), where each model makes predictions on `df1`\n    - estimators_2: List of tuples (name, model), where each model makes predictions on `df2`\n    - final_model: Trained neural network model for final predictions\n    - df1: DataFrame with features for the first set of estimators\n    - df2: DataFrame with features for the second set of estimators\n\n    Returns:\n    - Predictions from the final model\n    \"\"\"\n    # Generate predictions (labels and probabilities) from estimators_1\n    predictions_1_labels = np.array([np.argmax(model.predict_proba(df1), axis=1) for _, model in estimators_1]).T\n    predictions_1_probs = np.array([np.max(model.predict_proba(df1), axis=1) for _, model in estimators_1]).T\n    \n    df_tmp1_labels = pd.DataFrame(predictions_1_labels, columns=[name for name, _ in estimators_1])\n    df_tmp1_probs = pd.DataFrame(predictions_1_probs, columns=[name + '_prob' for name, _ in estimators_1])\n    df_x1 = pd.concat([df_tmp1_labels, df_tmp1_probs], axis=1)\n\n    # Generate predictions (labels and probabilities) from estimators_2\n    predictions_2_labels = np.array([np.argmax(model.predict_proba(df2), axis=1) for _, model in estimators_2]).T\n    predictions_2_probs = np.array([np.max(model.predict_proba(df2), axis=1) for _, model in estimators_2]).T\n    \n    df_tmp2_labels = pd.DataFrame(predictions_2_labels, columns=[name for name, _ in estimators_2])\n    df_tmp2_probs = pd.DataFrame(predictions_2_probs, columns=[name + '_prob' for name, _ in estimators_2])\n    df_x2 = pd.concat([df_tmp2_labels, df_tmp2_probs], axis=1)\n\n    # Concatenate both sets of predictions along with the input features for the final model\n    df_total = pd.concat([df1, df2, df_x1, df_x2], axis=1)\n    df_total.fillna(0, inplace=True)\n\n    # Use the final neural network model to make predictions\n    final_predictions = final_model.predict(df_total)\n\n    return final_predictions\n\ndef convert_number_to_category(label_encoder, predictions):\n    \"\"\"\n    Convert numerical predictions to categorical labels using a label encoder.\n    Parameters:\n    - label_encoder: Fitted LabelEncoder instance\n    - predictions: Numerical predictions from the final model\n    Returns:\n    - Array of categorical predictions\n    \"\"\"\n    return label_encoder.inverse_transform(predictions.argmax(axis=1))\n\ndef pre_process_dataframe_for_making_prediction(df):\n    \"\"\"\n    Preprocess input data by generating embeddings for prediction.\n    Parameters:\n    - df: Input DataFrame with a 'crimeaditionalinfo' column\n    Returns:\n    - df_1: DataFrame of embeddings generated by LaBSE\n    - df_2: DataFrame of embeddings generated by MPNet\n    \"\"\"\n    df_1 = generate_embeddings_labse(list(df['crimeaditionalinfo'].astype(str)))\n    df_2 = generate_embeddings_mpnet(list(df['crimeaditionalinfo'].astype(str)))\n    return df_1, df_2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Initialize the label encoders\nlabel_encoder_category = LabelEncoder()\nlabel_encoder_sub_category = LabelEncoder()\n\n# Fit the label encoders on unique values in each column\nlabel_encoder_category.fit(df['category'].unique())\nlabel_encoder_sub_category.fit(df['sub_category'].unique())\n\n# Transform the 'category' and 'sub_category' columns to numerical labels\ny_category = label_encoder_category.transform(df['category'])\ny_sub_category = label_encoder_sub_category.transform(df['sub_category'])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train classifiers for the 'category' labels\nestimators_labse_category_trained, estimators_mpnet_category_trained, nn_category_trained = train_classifiers(\n    estimators_labse_category, \n    estimators_mpnet_category, \n    embeddings_labse, \n    embeddings_mpnet, \n    y_category\n)\n\n# Train classifiers for the 'sub_category' labels\nestimators_labse_sub_category_trained, estimators_mpnet_sub_category_trained, nn_sub_category_trained = train_classifiers(\n    estimators_labse_sub_category, \n    estimators_mpnet_sub_category, \n    embeddings_labse, \n    embeddings_mpnet, \n    y_sub_category\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make prediction on missing values","metadata":{}},{"cell_type":"code","source":"X_test_sub_category = df_test[(df_test['sub_category'].isna()) & (df_test['crimeaditionalinfo'].notna())]\nX_test_sub_category_labse, X_test_sub_category_mnpt = pre_process_dataframe_for_making_prediction(X_test_subcategory)\ny_prediction_labeled = make_prediction(estimators_labse_sub_category_trained, estimators_mpnet_sub_category_trained, nn_sub_category_trained, X_test_sub_category_labse, X_test_sub_category_mnpt)\ny_prediction = convert_number_to_category(label_encoder_sub_category, y_prediction_labeled)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}